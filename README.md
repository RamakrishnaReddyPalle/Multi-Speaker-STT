# ğŸ™ï¸ **EchoSplit: Real-Time Audio Pipeline for Smarter Meeting Agents**

`EchoSplit` is my experimental, modular, and open-source pipeline designed to convert noisy, multi-speaker audio from online meetings into speaker-attributed text â€” enabling **LLM-powered meeting assistants** to generate better summaries, contextual actions, and agentic decisions.

---

## ğŸ” **Problem Statement - Idea**

In multi-speaker online meetings, raw audio streams are:

* Noisy (background hums, keyboards, fan noise),
* Overlapping (multiple speakers),
* Unstructured (no speaker identity),
* Not ideal for downstream LLM tasks.

To empower AI agents to assist with summaries, decisions, and follow-ups in **real-time**, we need a robust **preprocessing pipeline** that delivers clean, structured, speaker-wise transcriptions.

---

## âœ… Current Stage: **Noise Cancellation**

I've completed:

* âœ… Custom augmentation with multiple noise types
* âœ… Spectrogram-based visualization
* âœ… Denoising with DeepFilterNet v3
* âœ… CLI-based inference with RNNoise

---

## ğŸ”§ **Setup Instructions**

### âš™ï¸ **RNNoise Installation on Windows**

> Raw audio denoising using lightweight C-based RNN model

* ğŸ“¦ [RNNoise Gitlab](https://gitlab.xiph.org/xiph/rnnoise/)
* ğŸ§° [Install MSYS2](https://www.msys2.org/) and open MSYS2 64-bit terminal:

```bash
pacman -Syu  # then close and reopen
pacman -Su
pacman -S git make autoconf automake libtool gcc
```

* Then clone and build:

```bash
git clone https://gitlab.xiph.org/xiph/rnnoise.git
cd rnnoise
./autogen.sh
./configure
make
```

#### ğŸ” **Convert WAV â†” PCM (RNNoise CLI uses 48kHz 16-bit raw audio)**

```bash
ffmpeg -i noisy.wav -f s16le -acodec pcm_s16le -ac 1 -ar 48000 noisy.pcm
./examples/rnnoise_demo noisy.pcm denoised.pcm
ffmpeg -f s16le -ar 48000 -ac 1 -i denoised.pcm denoised.wav
```

---

### âš™ï¸ **DeepFilterNet Setup**

> PyTorch-based real-time deep noise suppressor

#### **Option 1: PyPI Installation (tested on Python 3.9.23)**

```bash
pip install deepfilternet
```

#### **Option 2: From GitHub Source**

```bash
git clone https://github.com/Rikorose/DeepFilterNet.git
cd DeepFilterNet
pip install ./DeepFilterNet
```

#### **For Local Usage:**

```python
import sys
sys.path.insert(0, "path/to/DeepFilterNet")
from df.enhance import enhance
from df.config.config import read_config
config = read_config()
enhance(config, input_path, output_path)
```

---

## ğŸ“ **Sample Data**

| Folder                        | Contents                                |
| ----------------------------- | --------------------------------------- |
| `augmented/`                  | Contains 7 variants of noisy test audio |
| `data/deepfilternet_outputs/` | Cleaned audio outputs for comparison    |

---

## ğŸ› ï¸ **Next Development Stages**

| Stage                            | Description                                      |
| -------------------------------- | ------------------------------------------------ |
| ğŸ”Š **Noise Suppression** (âœ“)     | DeepFilterNet + RNNoise benchmarking             |
| ğŸ”‰ **Speech Enhancement**        | Apply VoiceFixer or SEGAN                        |
| ğŸ§ **Speaker Separation**        | Use Demucs v4 / Conv-TasNet                      |
| ğŸ§  **STT (per speaker)**         | Whisper Tiny / Silero / NVIDIA NeMo              |
| ğŸ§‘â€ğŸ¤â€ğŸ§‘ **Speaker Diarization** | pyannote-audio or Wavesplit                      |
| ğŸ“ **LLM Feed Generation**       | Timestamped logs â†’ structured context            |
| ğŸ§© **Modular Serving**           | FastAPI endpoints / Chrome extension integration |

---

## ğŸš€ **Vision**

Turn online meeting audio into:

```json
[
  {"speaker": "A", "start": "00:00", "end": "00:05", "text": "Letâ€™s start the demo."},
  {"speaker": "B", "start": "00:06", "end": "00:09", "text": "Sure, loading now."}
]
```

...to empower **agentic AI assistants** with perfect memory, history, and intent.

---
## **Collaborations**
- [Vinay](https://github.com/Dvinaykumar6)
